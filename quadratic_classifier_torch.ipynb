{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "\n",
    "curr_directory = os.getcwd()\n",
    "\n",
    "# Player Roster Information (Copied over from player_roster.ipynb)\n",
    "teams = ['BOS','BRK','NYK','PHI','TOR','CHI','CLE','DET','IND','MIL','ATL','CHO','MIA','ORL','WAS',\n",
    "         'DEN','MIN','OKC','POR','UTA','GSW','LAC','LAL','PHO','SAC','DAL','HOU','MEM','NOP','SAS']\n",
    "        \n",
    "# Dictionary of roster\n",
    "# Ex. The roster of Boston Celtics players for the 2019-2020 season can be accessed using roster['BOS']['2019']\n",
    "# It does not include any players/rookies for which there is no season data\n",
    "roster = {}\n",
    "    \n",
    "for team in teams: \n",
    "    roster[team] = {}\n",
    "\n",
    "# Initialize set for list of all players (with no repeats)\n",
    "all_players = set()\n",
    "    \n",
    "for filename in os.listdir(os.path.join(curr_directory, 'data_sets/player_roster')):\n",
    "    data = pd.read_csv(os.path.join('data_sets/player_roster', filename))\n",
    "    year = filename[0:4]\n",
    "    \n",
    "    for team in teams:\n",
    "        roster[team][year] = []\n",
    "        \n",
    "        players = data.loc[data['Tm'] == team]\n",
    "        for ind in players.index: \n",
    "            player_name = players['Player'][ind].split('\\\\', 1)[0]\n",
    "            if player_name not in roster[team][year]: \n",
    "                roster[team][year].append(player_name)\n",
    "            \n",
    "        all_players.update(roster[team][year])\n",
    "\n",
    "num_players = len(all_players)\n",
    "        \n",
    "# Player dictionary that maps all players to index\n",
    "player_index = dict(zip(list(all_players), range(len(all_players))))\n",
    "\n",
    "game_data = pd.read_csv(os.path.join(curr_directory,'data_sets/nba.games.stats.csv'))\n",
    "\n",
    "# Sort all values by the Date\n",
    "game_data = game_data.sort_values(by=['Date'])\n",
    "\n",
    "game_results = np.array(list(game_data['TeamPoints'] - game_data['OpponentPoints']))\n",
    "teams = np.array(list(zip(game_data.Team, game_data.Opponent)))\n",
    "dates = np.array(list(game_data['Date']))\n",
    "\n",
    "# Remove duplicate games\n",
    "unique_dates = list(set(dates))\n",
    "repeat_indexes = []\n",
    "\n",
    "for date in unique_dates: \n",
    "    same_day = np.where(dates == date)\n",
    "    # suppose same_day = [0, 1, 2, 3, 4, 5]\n",
    "    for i in same_day[0]: \n",
    "        # start with i = 0\n",
    "        for j in same_day[0]: \n",
    "            # j = 0, 1, 2, 3, 4, 5\n",
    "            if j > i: \n",
    "                if np.array_equal(np.flip(teams[j], axis=0) , teams[i]): \n",
    "                    repeat_indexes.append(j)\n",
    "\n",
    "# Final dataset with unique games\n",
    "unique_game_results = game_results[repeat_indexes]\n",
    "unique_teams = teams[repeat_indexes]\n",
    "unique_dates = dates[repeat_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticRegression:\n",
    "    def __init__(self, step_size=1e-5, max_iter=1000, eps=1e-3, batch_size =32, theta=None, \n",
    "                  verbose=True):\n",
    "        \n",
    "        self.theta = theta\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.error_list = []\n",
    "        \n",
    "    def getSAS(self):\n",
    "        # Top left\n",
    "        S = np.array(self.theta[0:962, 0:962])\n",
    "        # Bottom right\n",
    "        S2 = np.array(self.theta[963:1925, 963:1925])\n",
    "        # Top right\n",
    "        A = np.array(self.theta[0:962, 963:1925])\n",
    "        # Bottom left\n",
    "        A2 = np.array(self.theta[963:1925, 0:962])\n",
    "        \n",
    "        return S,S2,A,A2\n",
    "\n",
    "    def predict(self, x): \n",
    "        z = x@self.theta@x.T \n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    def sigmoid(self, z): \n",
    "        return 1.0 / (1. + np.exp(-z))\n",
    "    \n",
    "    def loss_function_t(self, theta_t, x, y):\n",
    "        EPS = 1e-8\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        p = torch.sigmoid(x @ theta_t @ x.T)\n",
    "        return -1.*((y * torch.log(p + EPS) + (1-y) * torch.log(1 - p + EPS)).sum())\n",
    "    \n",
    "    def pytorch_gradient(self, x, y):\n",
    "        theta_t = torch.tensor(self.theta, requires_grad=True)\n",
    "        self.loss_function_t(theta_t, x, y).backward()\n",
    "        return theta_t.grad.numpy()\n",
    "    \n",
    "    def pytorch_batch_gradient(self, x_teams, y_teams, index): \n",
    "        x = x_teams[index::self.batch_size]\n",
    "        y = y_teams[index::self.batch_size]\n",
    "        \n",
    "        theta_t = torch.tensor(self.theta, requires_grad=True)\n",
    "        self.loss_function_t(theta_t, x, y).backward()\n",
    "        return theta_t.grad.numpy()\n",
    "    \n",
    "    def gradBatchLossFunction(self, x_teams, y_teams):\n",
    "        update = 0\n",
    "        theta = np.matrix(self.theta)\n",
    "        \n",
    "        for i in range(x_teams.shape[0]):\n",
    "            x = np.matrix(x_teams[i, :])\n",
    "            y = np.asscalar(y_teams[i])\n",
    "            update += x.T@x@theta@x.T@x - y*x.T@x\n",
    "            \n",
    "        return update\n",
    "    \n",
    "    def gradminiBatchLossFunction(self, x_teams, y_teams, batch_size, index):\n",
    "        update = 0\n",
    "        theta = np.matrix(self.theta)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            x = np.matrix(x_teams[int((i+index) % x_teams.shape[0]), :])\n",
    "            y = np.asscalar(y_teams[int((i+index) % x_teams.shape[0])])\n",
    "            update += x.T@x@theta@x.T@x - y*x.T@x\n",
    "            \n",
    "        return update\n",
    "    \n",
    "    def fit(self, x, y, mini = False):\n",
    "        iterations = 0\n",
    "        abs_error = 1\n",
    "        ind = 0\n",
    "        \n",
    "        if self.theta is None: \n",
    "            self.theta = np.zeros((2*num_players, 2*num_players))\n",
    "        \n",
    "        if mini == False:\n",
    "            while iterations < self.max_iter and abs_error >= self.eps and abs_error < 1000000:\n",
    "                error = self.step_size*self.pytorch_gradient(x, y)\n",
    "                abs_error = np.linalg.norm(error, 2)\n",
    "                self.error_list.append(abs_error)\n",
    "\n",
    "                theta_new = self.theta - error\n",
    "                self.theta = self.project(theta_new)\n",
    "\n",
    "                iterations += 1\n",
    "\n",
    "                print('Error {}: {}'.format(iterations, abs_error))\n",
    "        else:\n",
    "            batch_num = 1\n",
    "            while iterations < self.max_iter and abs_error >= self.eps and abs_error < 1000000:\n",
    "                error = self.step_size*self.pytorch_batch_gradient(x, y, self.batch_size, ind)\n",
    "                abs_error = np.linalg.norm(error, 2)\n",
    "                self.error_list.append(abs_error)\n",
    "\n",
    "                theta_new = self.theta - error\n",
    "                self.theta = self.project(theta_new)\n",
    "\n",
    "                iterations += 1\n",
    "                ind += 1\n",
    "\n",
    "                print('Error {}: {}'.format(iterations, abs_error))\n",
    "        \n",
    "        print('Convergence!')\n",
    "        plt.plot(self.error_list)\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Abs. Error')\n",
    "        plt.show()\n",
    "        \n",
    "    def process_data(self, teams, dates, results): \n",
    "        num_games = teams.shape[0]\n",
    "\n",
    "        # Create x for all games\n",
    "        # To access x for 0th game -- x[0, :] \n",
    "        x_without_intercept = np.zeros((num_games, 2*num_players))\n",
    "        \n",
    "        for i in range(num_games): \n",
    "            z, t = self.x_for_game(teams[i], dates[i])\n",
    "            combined = np.vstack((z, t))\n",
    "            x_without_intercept[i, :] = combined[:, 0]\n",
    "            \n",
    "        x = x_without_intercept\n",
    "        \n",
    "        # Create y for all games (if team A wins, y = 1; if team B wins, y = 0)\n",
    "        y = np.zeros((num_games, 1))\n",
    "        for i in range(num_games): \n",
    "            if results[i] > 0: \n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "                \n",
    "        return x, y\n",
    "\n",
    "    def x_for_game(self, teams, date): \n",
    "        x_1 = np.zeros((num_players, 1))\n",
    "        x_2 = np.zeros((num_players, 1))\n",
    "\n",
    "        if int(date[5:7]) < 9: \n",
    "            year = str(int(date[0:4]) - 1)\n",
    "        else: \n",
    "            year = date[0:4]\n",
    "\n",
    "        team_1_players = roster[teams[0]][year]\n",
    "        for item in team_1_players: \n",
    "            x_1[player_index[item]] = 1\n",
    "\n",
    "        team_2_players = roster[teams[1]][year]\n",
    "        for item in team_2_players: \n",
    "            x_2[player_index[item]] = 1\n",
    "\n",
    "        return x_1, x_2\n",
    "    \n",
    "    def add_intercept(self, x): \n",
    "        new_x = np.zeros((x.shape[0], x.shape[1] + 1))\n",
    "        new_x[:, 0] = 1\n",
    "        new_x[:, 1:] = x\n",
    "        \n",
    "        return new_x\n",
    "    \n",
    "    def symmetrize(self, m):\n",
    "        m = np.array(m)\n",
    "        for i in range(m.shape[0]):\n",
    "            for j in range(i, m.shape[1]):\n",
    "                m[i][j] = m[j][i] = 0.5*(m[j][i] + m[i][j])\n",
    "                \n",
    "        return m\n",
    "    \n",
    "    def antisymmetrize(self, m):\n",
    "        for i in range(m.shape[0]):\n",
    "            for j in range(i, m.shape[1]):\n",
    "                temp = m[i][j] - m[j][i]\n",
    "                m[i][j] = 0.5*temp\n",
    "                m[j][i] = -0.5*temp\n",
    "                \n",
    "        return m\n",
    "    \n",
    "    def project(self, m):\n",
    "        m = np.array(m)\n",
    "        side = m.shape[0]\n",
    "        S = self.symmetrize(m[0:int(side/2 - 1),0:int(side/2 - 1)])\n",
    "        S_minus = self.symmetrize(m[int(side/2):int(side-1), int(side/2):int(side-1)])\n",
    "\n",
    "        A = self.antisymmetrize(m[0:int(side/2-1), int(side/2):int(side-1)])\n",
    "        A_minus = self.antisymmetrize(m[int(side/2):int(side-1), 0:int(side/2-1)])\n",
    "        S_new = (S - S_minus)/2\n",
    "        S_minus_new = (S_minus - S)/2\n",
    "        \n",
    "        if np.allclose(A, -1*A_minus, 1e-10, 1e-10):\n",
    "            A_new = A\n",
    "            A_minus_new = A_minus\n",
    "        elif np.linalg.norm(A.T - A_minus, 2) < np.linalg.norm(A - A_minus, 2):\n",
    "            A_new = 0.5*(A + A_minus)\n",
    "            A_minus_new = A_new.T\n",
    "        else:\n",
    "            A_new = 0.5*(A + A_minus.T)\n",
    "            A_minus_new = A_new.T\n",
    "            \n",
    "        M = np.zeros(m.shape)\n",
    "        M[0:int(side/2 - 1),0:int(side/2 - 1)] = S_new\n",
    "        M[int(side/2):int(side-1),int(side/2):int(side - 1)] = S_minus_new\n",
    "        M[0:int(side/2 - 1),int(side/2):int(side - 1)] = A_new\n",
    "        M[int(side/2):int(side - 1),0:int(side/2 - 1)] = A_minus_new\n",
    "        \n",
    "        return M\n",
    "    \n",
    "    def general_predict(self, teams, dates, results): \n",
    "        test_x, test_y = self.process_data(teams, dates, results)\n",
    "        \n",
    "        predicted_y = []\n",
    "        for i in range(test_x.shape[0]):\n",
    "            x = test_x[i,:]           \n",
    "            prediction = self.predict(x)\n",
    "            if np.asscalar(prediction) > 0.5: \n",
    "                predicted_y.append(1)\n",
    "            else: \n",
    "                predicted_y.append(0)\n",
    "\n",
    "        predicted_y = np.array(predicted_y)\n",
    "        return np.mean(np.array(predicted_y) == np.array(test_y.T))\n",
    "    \n",
    "    def playoff_prediction(self, playoff_filename, playoff_date): \n",
    "        # Load playoff data\n",
    "        playoff_data = pd.read_csv(os.path.join(curr_directory, playoff_filename))\n",
    "\n",
    "        # Extract features of interest\n",
    "        raw_playoff_results = np.array(list(playoff_data['PTS'] - playoff_data['PTS.1']))\n",
    "        raw_playoff_team_pairs = np.array(list(zip(playoff_data['Visitor/Neutral'], playoff_data['Home/Neutral'])))\n",
    "        raw_playoff_dates = np.array(list(playoff_data['Date']))\n",
    "\n",
    "        playoff_pairs = {}\n",
    "\n",
    "        for i in range(len(raw_playoff_team_pairs)): \n",
    "            team_1 = raw_playoff_team_pairs[i][0]\n",
    "            team_2 = raw_playoff_team_pairs[i][1]\n",
    "            if (team_1,team_2) in playoff_pairs.keys(): \n",
    "                # if results > 0 --> team A won --> +1\n",
    "                # if results < 0 --> team B won --> -1\n",
    "                if raw_playoff_results[i] > 0: \n",
    "                    playoff_pairs[team_1,team_2] += 1\n",
    "                else: \n",
    "                    playoff_pairs[team_1,team_2] += -1\n",
    "            elif (team_2,team_1) in playoff_pairs.keys():\n",
    "                # if results > 0 --> team B won --> -1\n",
    "                # if results < 0 --> team A won --> +1\n",
    "                if raw_playoff_results[i] > 0: \n",
    "                    playoff_pairs[team_2,team_1] += -1\n",
    "                else: \n",
    "                    playoff_pairs[team_2,team_1] += 1\n",
    "            else: \n",
    "                if raw_playoff_results[i] > 0: \n",
    "                    playoff_pairs[team_1,team_2] = 1\n",
    "                else: \n",
    "                    playoff_pairs[team_1,team_2] = -1\n",
    "\n",
    "        playoff_teams = []\n",
    "        playoff_results = []\n",
    "        playoff_dates = []\n",
    "\n",
    "        for key in playoff_pairs: \n",
    "            playoff_teams.append([key[0], key[1]])\n",
    "            playoff_results.append(playoff_pairs[key])\n",
    "            playoff_dates.append(playoff_date)\n",
    "\n",
    "        playoff_teams = np.array(playoff_teams)\n",
    "        playoff_results = np.array(playoff_results)\n",
    "        playoff_dates = np.array(playoff_dates)\n",
    "\n",
    "        playoff_x, playoff_y = self.process_data(playoff_teams, playoff_dates, playoff_results)\n",
    "\n",
    "        predicted_y = []\n",
    "        for i in range(playoff_x.shape[0]):\n",
    "            x = playoff_x[i,:]\n",
    "            prediction = self.predict(x)\n",
    "            if np.asscalar(prediction) > 0.5: \n",
    "                predicted_y.append(1)\n",
    "            else: \n",
    "                predicted_y.append(0)\n",
    "\n",
    "        predicted_y = np.array(predicted_y)\n",
    "        prediction_accuracy = np.mean(np.array(predicted_y) == np.array(playoff_y.T[0][:]))\n",
    "\n",
    "        return prediction_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_tune(teams, dates, results, playoff_filename, date): \n",
    "    lr = [1e-3, 1e-4, 1e-5]\n",
    "    errors = {}\n",
    "    dev_accuracies = []\n",
    "    playoff_accuracies = []\n",
    "    n = teams.shape[0]\n",
    "    train_n = int(np.floor(0.8*n))\n",
    "    \n",
    "    for i in lr: \n",
    "        print('Learning rate: {}'.format(i))\n",
    "        # Initialize the model and process the data\n",
    "        model = QuadraticRegression(step_size=i)\n",
    "        teams_s, dates_s, results_s = shuffle(teams, dates, results, random_state=0)\n",
    "        x, y = model.process_data(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "        # Fit the model (w/o mini-batch) on training set\n",
    "        model.fit(x, y, mini=False)\n",
    "        errors[str(i)] = model.error_list\n",
    "        \n",
    "        dev_accuracy = model.general_predict(teams_s[train_n+1:n], dates_s[train_n+1:n], results_s[train_n+1:n])\n",
    "        dev_accuracies.append(dev_accuracy)\n",
    "        \n",
    "        playoff_accuracy = model.playoff_prediction(playoff_filename, date)\n",
    "        playoff_accuracies.append(playoff_accuracy)\n",
    "    \n",
    "    return errors, dev_accuracies, playoff_accuracies\n",
    "\n",
    "def learning_rate_tune_all(teams, dates, results): \n",
    "    lr = [1e-3, 1e-4, 1e-5]\n",
    "    errors = {}\n",
    "    dev_accuracies = []\n",
    "    n = teams.shape[0]\n",
    "    train_n = int(np.floor(0.8*n))\n",
    "    \n",
    "    for i in lr: \n",
    "        print('Learning rate: {}'.format(i))\n",
    "        # Initialize the model and process the data\n",
    "        model = QuadraticRegression(step_size=i, max_iters=1000)\n",
    "        teams_s, dates_s, results_s = shuffle(teams, dates, results, random_state=0)\n",
    "        x, y = model.process_data(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "        # Fit the model (w/o mini-batch) on training set\n",
    "        start = time.time()\n",
    "        model.fit(x, y, mini=False)\n",
    "        \n",
    "        errors[str(i)] = model.error_list\n",
    "        \n",
    "        dev_accuracy = model.general_predict(teams_s[train_n+1:n], dates[train_n+1:n], results_s[train_n+1:n])\n",
    "        dev_accuracies.append(dev_accuracy)\n",
    "    \n",
    "    return errors, dev_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Experiments\n",
    "\n",
    "# Full dataset\n",
    "teams_s, dates_s, results_s = shuffle(unique_teams, unique_dates, unique_game_results, random_state=0)\n",
    "train_n = 3935\n",
    "full_n = 4919\n",
    "\n",
    "# Runs w/o mini-batch for different learning rates (lr = 1E-6, 5E-7, 1E-7)\n",
    "print('Starting full batch descent with lr = 1E-6')\n",
    "model_lr_1e6 = QuadraticRegression(step_size = 1e-6, max_iter = 500)\n",
    "x_lr_1e6, y_lr_1e6= model_lr_1e6.process_data(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "start = time.time()\n",
    "model_lr_1e6.fit(x_lr_1e6, y_lr_1e6, mini=False)\n",
    "end = time.time()\n",
    "print('Time: {}'.format(end-start))\n",
    "train_accuracy_1e6 = model_lr_1e6.general_predict(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "dev_accuracy_1e6 = model_lr_1e6.general_predict(teams_s[train_n+1:full_n], dates_s[train_n+1:full_n], \n",
    "                                                results_s[train_n+1:full_n])\n",
    "errors_lr_1e6 = model_lr_1e6.error_list\n",
    "print('Train Accuracy: {}'.format(train_accuracy_1e6))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max_iters to be adjusted based on results above.\n",
    "print('Starting full batch descent with lr = 5E-7')\n",
    "model_lr_5e7 = QuadraticRegression(step_size = 5e-6, max_iter = 500)\n",
    "x_lr_5e7, y_lr_5e7= model_lr_5e7.process_data(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "start = time.time()\n",
    "model_lr_5e7.fit(x_lr_5e7, y_lr_5e7, mini=False)\n",
    "end = time.time()\n",
    "print('Time: {}'.format(end-start))\n",
    "train_accuracy_5e7 = model_lr_5e7.general_predict(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "dev_accuracy_5e7 = model_lr_5e7.general_predict(teams_s[train_n+1:full_n], dates_s[train_n+1:full_n], \n",
    "                                                results_s[train_n+1:full_n])\n",
    "errors_lr_5e7 = model_lr_5e7.error_list\n",
    "print('Train Accuracy: {}'.format(train_accuracy_5e7))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_5e7))\n",
    "\n",
    "print('Starting full batch descent with lr = 1E-7')\n",
    "model_lr_1e7 = QuadraticRegression(step_size = 1e-6, max_iter = 500)\n",
    "x_lr_1e7, y_lr_1e7= model_lr_1e7.process_data(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "start = time.time()\n",
    "model_lr_1e7.fit(x_lr_1e7, y_lr_1e7, mini=False)\n",
    "end = time.time()\n",
    "print('Time: {}'.format(end-start))\n",
    "train_accuracy_1e7 = model_lr_1e7.general_predict(teams_s[0:train_n], dates_s[0:train_n], results_s[0:train_n])\n",
    "dev_accuracy_1e7 = model_lr_1e7.general_predict(teams_s[train_n+1:full_n], dates_s[train_n+1:full_n], \n",
    "                                                results_s[train_n+1:full_n])\n",
    "errors_lr_1e7 = model_lr_1e7.error_list\n",
    "print('Train Accuracy: {}'.format(train_accuracy_1e7))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_1e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Season: 2014-2015')\n",
    "errors_2015, dev_2015, playoff_2015 = learning_rate_tune(unique_teams[0:1229], unique_dates[0:1229], \n",
    "                                                         unique_game_results[0:1229], 'data_sets/2015_playoffs.csv', '2015-04-10')\n",
    "print('Season: 2015-2016')\n",
    "errors_2016, dev_2016, playoff_2016 = learning_rate_tune(unique_teams[1230:2459], unique_dates[1230:2459], \n",
    "                                                         unique_game_results[1230:2459], 'data_sets/2016_playoffs.csv', '2016-04-10')\n",
    "print('Season: 2016-2017')\n",
    "errors_2017, dev_2017, playoff_2017 = learning_rate_tune(unique_teams[2460:3689], unique_dates[2460:3689], \n",
    "                                                         unique_game_results[2460:3689], 'data_sets/2017_playoffs.csv', '2017-04-10')\n",
    "print('Season: 2017-2018')\n",
    "errors_2018, dev_2018, playoff_2018 = learning_rate_tune(unique_teams[3690:4919], unique_dates[3690:4919], \n",
    "                                                         unique_game_results[3690:4919], 'data_sets/2018_playoffs.csv', '2018-04-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
