{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import time\n",
    "\n",
    "curr_directory = os.getcwd()\n",
    "#\n",
    "#\n",
    "#\n",
    "# Create index for all players + roster dictionaries\n",
    "#\n",
    "#\n",
    "# Player Roster Information (Copied over from player_roster.ipynb)\n",
    "teams = ['BOS','BRK','NYK','PHI','TOR','CHI','CLE','DET','IND','MIL','ATL','CHO','MIA','ORL','WAS',\n",
    "         'DEN','MIN','OKC','POR','UTA','GSW','LAC','LAL','PHO','SAC','DAL','HOU','MEM','NOP','SAS']\n",
    "        \n",
    "# Dictionary of roster\n",
    "# Ex. The roster of Boston Celtics players for the 2019-2020 season can be accessed using roster['BOS']['2019']\n",
    "# It does not include any players/rookies for which there is no season data\n",
    "roster = {}\n",
    "    \n",
    "for team in teams: \n",
    "    roster[team] = {}\n",
    "\n",
    "# Initialize set for list of all players (with no repeats)\n",
    "all_players = set()\n",
    "    \n",
    "for filename in os.listdir(os.path.join(curr_directory, 'data_sets/player_roster')):\n",
    "    data = pd.read_csv(os.path.join('data_sets/player_roster', filename))\n",
    "    year = filename[0:4]\n",
    "    \n",
    "    for team in teams:\n",
    "        roster[team][year] = []\n",
    "        \n",
    "        players = data.loc[data['Tm'] == team]\n",
    "        for ind in players.index: \n",
    "            player_name = players['Player'][ind].split('\\\\', 1)[0]\n",
    "            if player_name not in roster[team][year]: \n",
    "                roster[team][year].append(player_name)\n",
    "            \n",
    "        all_players.update(roster[team][year])\n",
    "\n",
    "num_players = len(all_players)\n",
    "        \n",
    "# Player dictionary that maps all players to index\n",
    "player_index = dict(zip(list(all_players), range(len(all_players))))\n",
    "#\n",
    "#\n",
    "#\n",
    "# Data Processing\n",
    "#\n",
    "#\n",
    "#\n",
    "# Game data from 2014 - 2015 season to 2017-2018 season\n",
    "game_data = pd.read_csv(os.path.join(curr_directory,'data_sets/nba.games.stats.csv'))\n",
    "\n",
    "# Sort all values by the Date\n",
    "game_data = game_data.sort_values(by=['Date'])\n",
    "\n",
    "# game has chronical order and Y shows score differential, X plus is team 1 payer\n",
    "# X minus is team 2 player\n",
    "game_results = np.array(list(game_data['TeamPoints'] - game_data['OpponentPoints']))\n",
    "teams = np.array(list(zip(game_data.Team, game_data.Opponent)))\n",
    "dates = np.array(list(game_data['Date']))\n",
    "\n",
    "unique_dates = list(set(dates))\n",
    "\n",
    "# Makes an index of all games that are repeated\n",
    "repeat_indexes = []\n",
    "\n",
    "for date in unique_dates: \n",
    "    same_day = np.where(dates == date)\n",
    "    # suppose same_day = [0, 1, 2, 3, 4, 5]\n",
    "    for i in same_day[0]: \n",
    "        # start with i = 0\n",
    "        for j in same_day[0]: \n",
    "            # j = 0, 1, 2, 3, 4, 5\n",
    "            if j > i: \n",
    "                if np.array_equal(np.flip(teams[j], axis=0) , teams[i]): \n",
    "                    repeat_indexes.append(j)\n",
    "\n",
    "# Make new unique game results, teams and dates arrays\n",
    "unique_game_results = game_results[repeat_indexes]\n",
    "unique_teams = teams[repeat_indexes]\n",
    "unique_dates = dates[repeat_indexes]\n",
    "#\n",
    "#\n",
    "#\n",
    "# Game data from the 2018-2019 season and the 2019-2020 season\n",
    "game_data_2018 = pd.read_csv(os.path.join(curr_directory,'data_sets/game_data_2018_2019.csv'))\n",
    "game_data_2019 = pd.read_csv(os.path.join(curr_directory,'data_sets/game_data_2019_2020.csv'))\n",
    "\n",
    "# Strip the day of week abbreviation from Date\n",
    "game_data_2018['Date'] = game_data_2018['Date'].str[4:]\n",
    "game_data_2019['Date'] = game_data_2019['Date'].str[4:]\n",
    "\n",
    "# Date conversion functions\n",
    "def monthToNum(shortMonth):\n",
    "    return{\n",
    "            'Jan' : '01',\n",
    "            'Feb' : '02',\n",
    "            'Mar' : '03',\n",
    "            'Apr' : '04',\n",
    "            'May' : '05',\n",
    "            'Jun' : '06',\n",
    "            'Jul' : '07',\n",
    "            'Aug' : '08',\n",
    "            'Sep' : '09', \n",
    "            'Oct' : '10',\n",
    "            'Nov' : '11',\n",
    "            'Dec' : '12'\n",
    "    }[shortMonth]\n",
    "\n",
    "def convert_dates(dataframe): \n",
    "    for i in range(dataframe['Date'].shape[0]): \n",
    "        if len(dataframe['Date'][i]) == 10: \n",
    "            year = dataframe['Date'][i][6:10]\n",
    "            date = '0' + dataframe['Date'][i][4]\n",
    "            month = monthToNum(dataframe['Date'][i][0:3])\n",
    "            dataframe.loc[i, 'Date'] = year + '-' + month + '-' + date\n",
    "        else: \n",
    "            year = dataframe['Date'][i][7:11]\n",
    "            date = dataframe['Date'][i][4:6]\n",
    "            month = monthToNum(dataframe['Date'][i][0:3])\n",
    "            dataframe.loc[i, 'Date'] = year + '-' + month + '-' + date\n",
    "\n",
    "convert_dates(game_data_2018)\n",
    "convert_dates(game_data_2019)\n",
    "\n",
    "game_results_2018 = np.array(list(game_data_2018['Visitor PTS'] - game_data_2018['Home PTS']))\n",
    "teams_2018 = np.array(list(zip(game_data_2018.Visitor, game_data_2018.Home)))\n",
    "dates_2018 = np.array(list(game_data_2018['Date']))\n",
    "\n",
    "game_results_2019 = np.array(list(game_data_2019['Visitor PTS'] - game_data_2019['Home PTS']))\n",
    "teams_2019 = np.array(list(zip(game_data_2019.Visitor, game_data_2019.Home)))\n",
    "dates_2019 = np.array(list(game_data_2019['Date']))\n",
    "#\n",
    "#\n",
    "#\n",
    "# Combine all data into one dataset\n",
    "#\n",
    "#\n",
    "#\n",
    "teams_all = np.concatenate((unique_teams, teams_2018, teams_2019), axis=0)\n",
    "dates_all = np.concatenate((unique_dates, dates_2018, dates_2019), axis=0)\n",
    "results_all = np.concatenate((unique_game_results, game_results_2018, game_results_2019), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticRegression:\n",
    "    def __init__(self, step_size=1e-5, max_iter=200, eps=1e-3, batch_size =32, theta=None, \n",
    "                  verbose=True):\n",
    "        \n",
    "        self.theta = theta\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.error_list = []\n",
    "        self.training_acc = []\n",
    "        self.dev_acc = []\n",
    "        \n",
    "    def getSAS(self):\n",
    "        # Top left\n",
    "        S = np.array(self.theta[0:962, 0:962])\n",
    "        # Bottom right\n",
    "        S2 = np.array(self.theta[963:1925, 963:1925])\n",
    "        # Top right\n",
    "        A = np.array(self.theta[0:962, 963:1925])\n",
    "        # Bottom left\n",
    "        A2 = np.array(self.theta[963:1925, 0:962])\n",
    "        \n",
    "        return S,S2,A,A2\n",
    "\n",
    "    def predict(self, x): \n",
    "        z = x@self.theta@x.T \n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    def sigmoid(self, z): \n",
    "        return 1.0 / (1. + np.exp(-z))\n",
    "    \n",
    "    def loss_function_t(self, theta_t, x, y):\n",
    "        EPS = 1e-8\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        p = torch.sigmoid(x @ theta_t @ x.T)\n",
    "        return -1.*((y * torch.log(p + EPS) + (1-y) * torch.log(1 - p + EPS)).sum())\n",
    "    \n",
    "    def pytorch_gradient(self, x, y):\n",
    "        theta_t = torch.tensor(self.theta, requires_grad=True)\n",
    "        self.loss_function_t(theta_t, x, y).backward()\n",
    "        return theta_t.grad.numpy()\n",
    "    \n",
    "    def pytorch_batch_gradient(self, x_teams, y_teams, index): \n",
    "        x = x_teams[index::self.batch_size]\n",
    "        y = y_teams[index::self.batch_size]\n",
    "        \n",
    "        theta_t = torch.tensor(self.theta, requires_grad=True)\n",
    "        self.loss_function_t(theta_t, x, y).backward()\n",
    "        return theta_t.grad.numpy()\n",
    "    \n",
    "    def gradBatchLossFunction(self, x_teams, y_teams):\n",
    "        update = 0\n",
    "        theta = np.matrix(self.theta)\n",
    "        \n",
    "        for i in range(x_teams.shape[0]):\n",
    "            x = np.matrix(x_teams[i, :])\n",
    "            y = np.asscalar(y_teams[i])\n",
    "            update += x.T@x@theta@x.T@x - y*x.T@x\n",
    "            \n",
    "        return update\n",
    "    \n",
    "    def gradminiBatchLossFunction(self, x_teams, y_teams, batch_size, index):\n",
    "        update = 0\n",
    "        theta = np.matrix(self.theta)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            x = np.matrix(x_teams[int((i+index) % x_teams.shape[0]), :])\n",
    "            y = np.asscalar(y_teams[int((i+index) % x_teams.shape[0])])\n",
    "            update += x.T@x@theta@x.T@x - y*x.T@x\n",
    "            \n",
    "        return update\n",
    "    \n",
    "    def fit(self, x, y, dev_x, dev_y, mini = False):\n",
    "        iterations = 0\n",
    "        abs_error = 1\n",
    "        ind = 0\n",
    "        \n",
    "        if self.theta is None: \n",
    "            self.theta = np.zeros((2*num_players, 2*num_players))\n",
    "        \n",
    "        if mini == False:\n",
    "            while iterations < self.max_iter and abs_error >= self.eps and abs_error < 1000000:\n",
    "                error = self.step_size*self.pytorch_gradient(x, y)\n",
    "                abs_error = np.linalg.norm(error, 2)\n",
    "                self.error_list.append(abs_error)\n",
    "\n",
    "                theta_new = self.theta - error\n",
    "                self.theta = self.project(theta_new)\n",
    "\n",
    "                iterations += 1\n",
    "                \n",
    "                train_accuracy = self.training_predict(x, y)\n",
    "                self.training_acc.append(train_accuracy)\n",
    "                dev_accuracy = self.training_predict(dev_x, dev_y)\n",
    "                self.dev_acc.append(dev_accuracy)\n",
    "\n",
    "                print('Error {}: {}'.format(iterations, abs_error))\n",
    "                print('Training Accuracy: {}'.format(train_accuracy))\n",
    "                print('Dev Accuracy: {}'.format(dev_accuracy))\n",
    "        else:\n",
    "            batch_num = 1\n",
    "            while iterations < self.max_iter and abs_error >= self.eps and abs_error < 1000000:\n",
    "                error = self.step_size*self.pytorch_batch_gradient(x, y, self.batch_size, ind)\n",
    "                abs_error = np.linalg.norm(error, 2)\n",
    "                self.error_list.append(abs_error)\n",
    "\n",
    "                theta_new = self.theta - error\n",
    "                self.theta = self.project(theta_new)\n",
    "\n",
    "                iterations += 1\n",
    "                ind += 1\n",
    "\n",
    "                print('Error {}: {}'.format(iterations, abs_error))\n",
    "        \n",
    "        print('Convergence!')\n",
    "        plt.style.use('seaborn-darkgrid')\n",
    "        plt.plot(self.training_acc, color = 'firebrick', label='Training Accuracy')\n",
    "        plt.plot(self.dev_acc, color = 'teal', label='Dev Accuracy')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.show()\n",
    "        \n",
    "    def process_data(self, teams, dates, results): \n",
    "        num_games = teams.shape[0]\n",
    "\n",
    "        # Create x for all games\n",
    "        # To access x for 0th game -- x[0, :] \n",
    "        x_without_intercept = np.zeros((num_games, 2*num_players))\n",
    "        \n",
    "        for i in range(num_games): \n",
    "            z, t = self.x_for_game(teams[i], dates[i])\n",
    "            combined = np.vstack((z, t))\n",
    "            x_without_intercept[i, :] = combined[:, 0]\n",
    "            \n",
    "        x = x_without_intercept\n",
    "        \n",
    "        # Create y for all games (if team A wins, y = 1; if team B wins, y = 0)\n",
    "        y = np.zeros((num_games, 1))\n",
    "        for i in range(num_games): \n",
    "            if results[i] > 0: \n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "                \n",
    "        return x, y\n",
    "\n",
    "    def x_for_game(self, teams, date): \n",
    "        x_1 = np.zeros((num_players, 1))\n",
    "        x_2 = np.zeros((num_players, 1))\n",
    "\n",
    "        if int(date[5:7]) < 9: \n",
    "            year = str(int(date[0:4]) - 1)\n",
    "        else: \n",
    "            year = date[0:4]\n",
    "\n",
    "        team_1_players = roster[teams[0]][year]\n",
    "        for item in team_1_players: \n",
    "            x_1[player_index[item]] = 1\n",
    "\n",
    "        team_2_players = roster[teams[1]][year]\n",
    "        for item in team_2_players: \n",
    "            x_2[player_index[item]] = 1\n",
    "\n",
    "        return x_1, x_2\n",
    "    \n",
    "    def add_intercept(self, x): \n",
    "        new_x = np.zeros((x.shape[0], x.shape[1] + 1))\n",
    "        new_x[:, 0] = 1\n",
    "        new_x[:, 1:] = x\n",
    "        \n",
    "        return new_x\n",
    "    \n",
    "    def symmetrize(self, m):\n",
    "        m = np.array(m)\n",
    "        for i in range(m.shape[0]):\n",
    "            for j in range(i, m.shape[1]):\n",
    "                m[i][j] = m[j][i] = 0.5*(m[j][i] + m[i][j])\n",
    "                \n",
    "        return m\n",
    "    \n",
    "    def antisymmetrize(self, m):\n",
    "        for i in range(m.shape[0]):\n",
    "            for j in range(i, m.shape[1]):\n",
    "                temp = m[i][j] - m[j][i]\n",
    "                m[i][j] = 0.5*temp\n",
    "                m[j][i] = -0.5*temp\n",
    "                \n",
    "        return m\n",
    "    \n",
    "    def project(self, m):\n",
    "        m = np.array(m)\n",
    "        side = m.shape[0]\n",
    "        S = self.symmetrize(m[0:int(side/2 - 1),0:int(side/2 - 1)])\n",
    "        S_minus = self.symmetrize(m[int(side/2):int(side-1), int(side/2):int(side-1)])\n",
    "\n",
    "        A = self.antisymmetrize(m[0:int(side/2-1), int(side/2):int(side-1)])\n",
    "        A_minus = self.antisymmetrize(m[int(side/2):int(side-1), 0:int(side/2-1)])\n",
    "        S_new = (S - S_minus)/2\n",
    "        S_minus_new = (S_minus - S)/2\n",
    "        \n",
    "        if np.allclose(A, -1*A_minus, 1e-10, 1e-10):\n",
    "            A_new = A\n",
    "            A_minus_new = A_minus\n",
    "        elif np.linalg.norm(A.T - A_minus, 2) < np.linalg.norm(A - A_minus, 2):\n",
    "            A_new = 0.5*(A + A_minus)\n",
    "            A_minus_new = A_new.T\n",
    "        else:\n",
    "            A_new = 0.5*(A + A_minus.T)\n",
    "            A_minus_new = A_new.T\n",
    "            \n",
    "        M = np.zeros(m.shape)\n",
    "        M[0:int(side/2 - 1),0:int(side/2 - 1)] = S_new\n",
    "        M[int(side/2):int(side-1),int(side/2):int(side - 1)] = S_minus_new\n",
    "        M[0:int(side/2 - 1),int(side/2):int(side - 1)] = A_new\n",
    "        M[int(side/2):int(side - 1),0:int(side/2 - 1)] = A_minus_new\n",
    "        \n",
    "        return M\n",
    "    \n",
    "    def training_predict(self, test_x, test_y): \n",
    "        predicted_y = []\n",
    "        for i in range(test_x.shape[0]):\n",
    "            x = test_x[i,:]\n",
    "            prediction = self.predict(x)\n",
    "            if np.asscalar(prediction) > 0.5: \n",
    "                predicted_y.append(1)\n",
    "            else: \n",
    "                predicted_y.append(0)\n",
    "\n",
    "        predicted_y = np.array(predicted_y)\n",
    "        return np.mean(np.array(predicted_y) == np.array(test_y.T))\n",
    "    \n",
    "    def general_predict(self, teams, dates, results): \n",
    "        test_x, test_y = self.process_data(teams, dates, results)\n",
    "        \n",
    "        predicted_y = []\n",
    "        for i in range(test_x.shape[0]):\n",
    "            x = test_x[i,:]           \n",
    "            prediction = self.predict(x)\n",
    "            if np.asscalar(prediction) > 0.5: \n",
    "                predicted_y.append(1)\n",
    "            else: \n",
    "                predicted_y.append(0)\n",
    "\n",
    "        predicted_y = np.array(predicted_y)\n",
    "        return np.mean(np.array(predicted_y) == np.array(test_y.T))\n",
    "    \n",
    "    def playoff_prediction(self, playoff_filename, playoff_date): \n",
    "        # Load playoff data\n",
    "        playoff_data = pd.read_csv(os.path.join(curr_directory, playoff_filename))\n",
    "\n",
    "        # Extract features of interest\n",
    "        raw_playoff_results = np.array(list(playoff_data['PTS'] - playoff_data['PTS.1']))\n",
    "        raw_playoff_team_pairs = np.array(list(zip(playoff_data['Visitor/Neutral'], playoff_data['Home/Neutral'])))\n",
    "        raw_playoff_dates = np.array(list(playoff_data['Date']))\n",
    "\n",
    "        playoff_pairs = {}\n",
    "\n",
    "        for i in range(len(raw_playoff_team_pairs)): \n",
    "            team_1 = raw_playoff_team_pairs[i][0]\n",
    "            team_2 = raw_playoff_team_pairs[i][1]\n",
    "            if (team_1,team_2) in playoff_pairs.keys(): \n",
    "                # if results > 0 --> team A won --> +1\n",
    "                # if results < 0 --> team B won --> -1\n",
    "                if raw_playoff_results[i] > 0: \n",
    "                    playoff_pairs[team_1,team_2] += 1\n",
    "                else: \n",
    "                    playoff_pairs[team_1,team_2] += -1\n",
    "            elif (team_2,team_1) in playoff_pairs.keys():\n",
    "                # if results > 0 --> team B won --> -1\n",
    "                # if results < 0 --> team A won --> +1\n",
    "                if raw_playoff_results[i] > 0: \n",
    "                    playoff_pairs[team_2,team_1] += -1\n",
    "                else: \n",
    "                    playoff_pairs[team_2,team_1] += 1\n",
    "            else: \n",
    "                if raw_playoff_results[i] > 0: \n",
    "                    playoff_pairs[team_1,team_2] = 1\n",
    "                else: \n",
    "                    playoff_pairs[team_1,team_2] = -1\n",
    "\n",
    "        playoff_teams = []\n",
    "        playoff_results = []\n",
    "        playoff_dates = []\n",
    "\n",
    "        for key in playoff_pairs: \n",
    "            playoff_teams.append([key[0], key[1]])\n",
    "            playoff_results.append(playoff_pairs[key])\n",
    "            playoff_dates.append(playoff_date)\n",
    "\n",
    "        playoff_teams = np.array(playoff_teams)\n",
    "        playoff_results = np.array(playoff_results)\n",
    "        playoff_dates = np.array(playoff_dates)\n",
    "\n",
    "        playoff_x, playoff_y = self.process_data(playoff_teams, playoff_dates, playoff_results)\n",
    "\n",
    "        predicted_y = []\n",
    "        for i in range(playoff_x.shape[0]):\n",
    "            x = playoff_x[i,:]\n",
    "            prediction = self.predict(x)\n",
    "            if np.asscalar(prediction) > 0.5: \n",
    "                predicted_y.append(1)\n",
    "            else: \n",
    "                predicted_y.append(0)\n",
    "\n",
    "        predicted_y = np.array(predicted_y)\n",
    "        prediction_accuracy = np.mean(np.array(predicted_y) == np.array(playoff_y.T[0][:]))\n",
    "\n",
    "        return prediction_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_s, dates_s, results_s = shuffle(teams_all, dates_all, results_all, random_state=0)\n",
    "# 64% training, 16% dev, 20% test\n",
    "n_train = 4159\n",
    "n_dev = 5199\n",
    "n_full = 6500\n",
    "\n",
    "teams_train = teams_s[0:n_train]\n",
    "dates_train = dates_s[0:n_train]\n",
    "results_train = results_s[0:n_train]\n",
    "\n",
    "teams_dev = teams_s[n_train + 1:n_dev]\n",
    "dates_dev = dates_s[n_train + 1:n_dev]\n",
    "results_dev = results_s[n_train + 1:n_dev]\n",
    "\n",
    "teams_test = teams_s[n_dev + 1:n_full]\n",
    "dates_test = dates_s[n_dev + 1:n_full]\n",
    "results_test = results_s[n_dev + 1:n_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lr = 2E-6')\n",
    "model_lr_2e6 = QuadraticRegression(step_size = 2e-6, max_iter = 20)\n",
    "x_lr_2e6, y_lr_2e6= model_lr_2e6.process_data(teams_train, dates_train, results_train)\n",
    "dev_x_2e6, dev_y_2e6 = model_lr_2e6.process_data(teams_dev, dates_dev, results_dev)\n",
    "model_lr_2e6.fit(x_lr_2e6, y_lr_2e6, dev_x_2e6, dev_y_2e6)\n",
    "\n",
    "train_accuracy_2e6 = model_lr_2e6.general_predict(teams_train, dates_train, results_train)\n",
    "dev_accuracy_2e6 = model_lr_2e6.general_predict(teams_dev, dates_dev, results_dev)\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_2e6))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_2e6))\n",
    "\n",
    "np.savetxt('full_dataset_lr_2e6.txt', np.array(model_lr_2e6.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lr = 1E-6')\n",
    "model_lr_1e6 = QuadraticRegression(step_size = 1e-6, max_iter = 200)\n",
    "x_lr_1e6, y_lr_1e6= model_lr_1e6.process_data(teams_train, dates_train, results_train)\n",
    "model_lr_1e6.fit(x_lr_1e6, y_lr_1e6)\n",
    "\n",
    "train_accuracy_1e6 = model_lr_1e6.general_predict(teams_train, dates_train, results_train)\n",
    "dev_accuracy_1e6 = model_lr_1e6.general_predict(teams_dev, dates_dev, results_dev)\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_1e6))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_1e6))\n",
    "\n",
    "np.savetxt('full_dataset_lr_1e6.txt', np.array(model_lr_1e6.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lr = 5E-7')\n",
    "model_lr_5e7 = QuadraticRegression(step_size = 5e-7, max_iter = 200)\n",
    "x_lr_5e7, y_lr_5e7= model_lr_5e7.process_data(teams_train, dates_train, results_train)\n",
    "model_lr_5e7.fit(x_lr_5e7, y_lr_5e7)\n",
    "\n",
    "train_accuracy_5e7 = model_lr_5e7.general_predict(teams_train, dates_train, results_train)\n",
    "dev_accuracy_5e7 = model_lr_5e7.general_predict(teams_dev, dates_dev, results_dev)\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_5e7))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_5e7))\n",
    "\n",
    "np.savetxt('full_dataset_lr_5e7.txt', np.array(model_lr_5e7.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual season analysis -- best learning rate is 2E-6 (determined by previous experiments in quadratic_classifier_torch.ipynb)\n",
    "n_train_s = 983\n",
    "n_dev_s = 1229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014-2015 Season\n",
    "teams_2014, dates_2014, results_2014 = shuffle(teams_all[0:1229], dates_all[0:1229], results_all[0:1229], random_state=0)\n",
    "\n",
    "teams_train_2014 = teams_2014[0:n_train_s]\n",
    "dates_train_2014 = dates_2014[0:n_train_s]\n",
    "results_train_2014 = results_2014[0:n_train_s]\n",
    "\n",
    "teams_dev_2014 = teams_2014[n_train_s + 1:n_dev_s]\n",
    "dates_dev_2014 = dates_2014[n_train_s + 1:n_dev_s]\n",
    "results_dev_2014 = results_2014[n_train_s + 1:n_dev_s]\n",
    "\n",
    "print('Season: 2014-2015')\n",
    "model_2014 = QuadraticRegression(step_size = 2e-6, max_iter = 250)\n",
    "x_2014, y_2014 = model_2014.process_data(teams_train_2014, dates_train_2014, results_train_2014)\n",
    "model_2014.fit(x_2014, y_2014)\n",
    "\n",
    "train_accuracy_2014 = model_2014.general_predict(teams_train_2014, dates_train_2014, results_train_2014)\n",
    "dev_accuracy_2014 = model_2014.general_predict(teams_dev_2014, dates_dev_2014, results_dev_2014)\n",
    "test_accuracy_2014 = model_2014.playoff_prediction('data_sets/2015_playoffs.csv', '2015-04-10')\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_2014))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_2014))\n",
    "print('Playoff Accuracy: {}'.format(test_accuracy_2014))\n",
    "\n",
    "np.savetxt('2014_2015_lr_2e6.txt', np.array(model_2014.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015-2016 Season\n",
    "teams_2015, dates_2015, results_2015 = shuffle(teams_all[1230:2459], dates_all[1230:2459], results_all[1230:2459], random_state=0)\n",
    "\n",
    "teams_train_2015 = teams_2015[0:n_train_s]\n",
    "dates_train_2015 = dates_2015[0:n_train_s]\n",
    "results_train_2015 = results_2015[0:n_train_s]\n",
    "\n",
    "teams_dev_2015 = teams_2015[n_train_s + 1:n_dev_s]\n",
    "dates_dev_2015 = dates_2015[n_train_s + 1:n_dev_s]\n",
    "results_dev_2015 = results_2015[n_train_s + 1:n_dev_s]\n",
    "\n",
    "print('Season: 2015-2016')\n",
    "model_2015 = QuadraticRegression(step_size = 2e-6, max_iter = 250)\n",
    "x_2015, y_2015 = model_2015.process_data(teams_train_2015, dates_train_2015, results_train_2015)\n",
    "model_2015.fit(x_2015, y_2015)\n",
    "\n",
    "train_accuracy_2015 = model_2015.general_predict(teams_train_2015, dates_train_2015, results_train_2015)\n",
    "dev_accuracy_2015 = model_2015.general_predict(teams_dev_2015, dates_dev_2015, results_dev_2015)\n",
    "test_accuracy_2015 = model_2015.playoff_prediction('data_sets/2016_playoffs.csv', '2016-04-10')\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_2015))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_2015))\n",
    "print('Playoff Accuracy: {}'.format(test_accuracy_2015))\n",
    "\n",
    "np.savetxt('2015_2016_lr_2e6.txt', np.array(model_2015.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016-2017 Season\n",
    "teams_2016, dates_2016, results_2016 = shuffle(teams_all[2460:3689], dates_all[2460:3689], results_all[2460:3689], random_state=0)\n",
    "\n",
    "teams_train_2016 = teams_2016[0:n_train_s]\n",
    "dates_train_2016 = dates_2016[0:n_train_s]\n",
    "results_train_2016 = results_2016[0:n_train_s]\n",
    "\n",
    "teams_dev_2016 = teams_2016[n_train_s + 1:n_dev_s]\n",
    "dates_dev_2016 = dates_2016[n_train_s + 1:n_dev_s]\n",
    "results_dev_2016 = results_2016[n_train_s + 1:n_dev_s]\n",
    "\n",
    "print('Season: 2016-2017')\n",
    "model_2016 = QuadraticRegression(step_size = 2e-6, max_iter = 250)\n",
    "x_2016, y_2016 = model_2016.process_data(teams_train_2016, dates_train_2016, results_train_2016)\n",
    "model_2016.fit(x_2016, y_2016)\n",
    "\n",
    "train_accuracy_2016 = model_2016.general_predict(teams_train_2016, dates_train_2016, results_train_2016)\n",
    "dev_accuracy_2016 = model_2016.general_predict(teams_dev_2016, dates_dev_2016, results_dev_2016)\n",
    "test_accuracy_2016 = model_2016.playoff_prediction('data_sets/2017_playoffs.csv', '2017-04-10')\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_2016))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_2016))\n",
    "print('Playoff Accuracy: {}'.format(test_accuracy_2016))\n",
    "\n",
    "np.savetxt('2016_2017_lr_2e6.txt', np.array(model_2016.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017-2018 Season\n",
    "teams_2017, dates_2017, results_2017 = shuffle(teams_all[3690:4919], dates_all[3690:4919], results_all[3690:4919], random_state=0)\n",
    "\n",
    "teams_train_2017 = teams_2017[0:n_train_s]\n",
    "dates_train_2017 = dates_2017[0:n_train_s]\n",
    "results_train_2017 = results_2017[0:n_train_s]\n",
    "\n",
    "teams_dev_2017 = teams_2017[n_train_s + 1:n_dev_s]\n",
    "dates_dev_2017 = dates_2017[n_train_s + 1:n_dev_s]\n",
    "results_dev_2017 = results_2017[n_train_s + 1:n_dev_s]\n",
    "\n",
    "print('Season: 2017-2018')\n",
    "model_2017 = QuadraticRegression(step_size = 2e-6, max_iter = 250)\n",
    "x_2017, y_2017 = model_2017.process_data(teams_train_2017, dates_train_2017, results_train_2017)\n",
    "model_2017.fit(x_2017, y_2017)\n",
    "\n",
    "train_accuracy_2017 = model_2017.general_predict(teams_train_2017, dates_train_2017, results_train_2017)\n",
    "dev_accuracy_2017 = model_2017.general_predict(teams_dev_2017, dates_dev_2017, results_dev_2017)\n",
    "test_accuracy_2017 = model_2017.playoff_prediction('data_sets/2018_playoffs.csv', '2018-04-10')\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_2017))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_2017))\n",
    "print('Playoff Accuracy: {}'.format(test_accuracy_2017))\n",
    "\n",
    "np.savetxt('2017_2018_lr_2e6.txt', np.array(model_2017.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018-2019 Season\n",
    "teams_2018, dates_2018, results_2018 = shuffle(teams_all[4920:6149], dates_all[4920:6149], results_all[4920:6149], random_state=0)\n",
    "\n",
    "teams_train_2018 = teams_2018[0:n_train_s]\n",
    "dates_train_2018 = dates_2018[0:n_train_s]\n",
    "results_train_2018 = results_2018[0:n_train_s]\n",
    "\n",
    "teams_dev_2018 = teams_2018[n_train_s + 1:n_dev_s]\n",
    "dates_dev_2018 = dates_2018[n_train_s + 1:n_dev_s]\n",
    "results_dev_2018 = results_2018[n_train_s + 1:n_dev_s]\n",
    "\n",
    "print('Season: 2017-2018')\n",
    "model_2018 = QuadraticRegression(step_size = 2e-6, max_iter = 250)\n",
    "x_2018, y_2018 = model_2018.process_data(teams_train_2018, dates_train_2018, results_train_2018)\n",
    "model_2018.fit(x_2018, y_2018)\n",
    "\n",
    "train_accuracy_2018 = model_2018.general_predict(teams_train_2018, dates_train_2018, results_train_2018)\n",
    "dev_accuracy_2018 = model_2018.general_predict(teams_dev_2018, dates_dev_2018, results_dev_2018)\n",
    "test_accuracy_2018 = model_2018.playoff_prediction('data_sets/2019_playoffs.csv', '2019-04-10')\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_accuracy_2018))\n",
    "print('Dev Accuracy: {}'.format(dev_accuracy_2018))\n",
    "print('Playoff Accuracy: {}'.format(test_accuracy_2018))\n",
    "\n",
    "np.savetxt('2018_2019_lr_2e6.txt', np.array(model_2018.error_list), delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
